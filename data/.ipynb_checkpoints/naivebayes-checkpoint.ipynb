{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Naïve Bayes – Additional Advice\n",
    "This notebook guides you through multiple steps you can follow to create a naïve Bayes classifier. After following these steps you will still need to collate and move your code into the main assignment notebook file so that it meets the required format.\n",
    "\n",
    "Read each step (including the maths!) carefully.\n",
    "\n",
    "You can implement a naïve Bayes classifier without following this advice.\n",
    "\n",
    "This notebook will not be graded and does not need to be submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 1.]]\n",
      "[[1. 0. 0. ... 1. 1. 1.]\n",
      " [1. 1. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "training_spam = np.loadtxt(open(\"training_spam.csv\"), delimiter=\",\")\n",
    "testing_spam = np.loadtxt(open(\"testing_spam.csv\"), delimiter=\",\")\n",
    "\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "\n",
    "print(training_spam)\n",
    "print(testing_spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The model:  naïve Bayes\n",
    "Your [naïve Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier will distinguish between two classes:\n",
    "\n",
    "* $C = 1$ for spam messages\n",
    "* $C = 0$ for ham messages\n",
    "\n",
    "\n",
    "The classifier builds a model for the probability $p(C=c\\ |\\ \\text{message})$ that a given message belongs to a certain class. A new message is then classified based on the Bayesian *maximum a posteriori* estimate\n",
    "$\\require{color}$\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\{0,1\\}}{\\operatorname{argmax}} \\  \\textcolor{blue}{p(C=c\\ |\\ \\text{message})}.\n",
    "\\end{equation}\n",
    "Using Bayes' rule we can write\n",
    "\n",
    "\\begin{equation}\n",
    "p(C=c\\ |\\ \\text{message}) = \\frac{p(\\text{message}\\ |\\ C=c)p(C=c)}{p(\\text{message}\\ |\\ C=1)p(C=1) + p(\\text{message}\\ |\\ C=0)p(C=0)}.  \\quad \\quad \n",
    "\\end{equation}\n",
    "\n",
    "The denominator is the same for both classes and we can thus drop it to get\n",
    "\n",
    "\\begin{equation}\n",
    "\\textcolor{blue}{p(C=c\\ |\\ \\text{message})} \\propto \\textcolor{orange}{p(\\text{message}\\ |\\ C=c)}\\textcolor{green}{p(C=c)},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\propto$ means \"proportional to\". The class priors $\\textcolor{green}{p(C=c)}$ can be computed directly (you will do so in exercise A) but we need to further simplify $\\textcolor{orange}{p(\\text{message} \\ |\\ C=c)}$.\n",
    "\n",
    "\n",
    "### Choice of the event model: *Multinomial* naïve Bayes\n",
    "\n",
    "Different naïve Bayes models differ in their distributional assumptions about $\\textcolor{orange}{p(\\text{message}\\ |\\ C=c)}$. We represent a message using a **binary** [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) model. Specifically, a message is represented as a set of $k$ keywords, that is, $message = (w_1, ..., w_k)$, where $w_i = 1$ if the  keyword $w_i$ appears in the message and $w_i = 0$ otherwise.\n",
    "\n",
    "We assume that the $p(w_1, ..., w_k |\\ C=c)$ follows a [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution) for each class. Don't let the name scare you, this model simply assigns probabilities to different counts of events with multiple outcomes. So for example: \"I roll a biased six-sided die six times, what is the probability that I get each side occurring exactly once\" is a question that can be answered with a multinomial distribution. You don't need to understand all of the equations on the Wikipedia page.\n",
    "\n",
    "Intuitively, the multinomial distribution assumes that the words of a message were \"drawn\" independently from a bag of $k$ different words. Depending on the class membership $c$, each keyword $w$ has a probability $\\theta_{c, w}$ of being drawn. For example,\n",
    "\n",
    "* $\\theta_{spam, w}$ will have high value for $w \\in \\{$bank, transfer, buy,... $\\}$.\n",
    "* $\\theta_{ham, w}$ will have high value for $w \\in \\{$paper, conference, proposal, experiment,... $\\}$, if the training data was mostly gathered from emails of researchers.\n",
    "\n",
    "Under these assumptions, the likelihood of a message, given that it belongs to class $c$, is then proportional to\n",
    "\\begin{equation}\n",
    "\\textcolor{orange}{p(\\text{message}\\ |\\ C=c)} \\propto \\prod_{i = 1}^k  \\left(\\textcolor{brown}{\\theta_{c, w_i}} \\right)^{w_i}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The parameters $\\textcolor{brown}{\\theta_{c, w}}$ are estimated by counting the relative frequencies in the training data. Use **Laplace-smoothing** with $\\alpha = 1$ (add-one smoothing), that is,\n",
    "\\begin{equation}\n",
    "\\textcolor{brown}{\\theta_{c, w}} = \\frac{n_{c, w} + \\alpha}{n_{c} + k \\alpha},\n",
    "\\end{equation}\n",
    "where $n_{c, w}$ is the number of times the keyword $w$ appears in messages of class $c$ in the training set and $n_{c}$ is the total count of keywords for all messages of class $c$, that is, $n_{c} = \\sum_w n_{c, w}$.\n",
    "\n",
    "\n",
    "\n",
    "We are now finally able to rewrite the *maximum a posteriori* estimate in a form that is easy to compute:\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\{0,1\\}}{\\operatorname{argmax}} \\ \\left[ \\textcolor{green}{p(C=c)}   \\prod_{i = 1}^k  \\left(\\textcolor{brown}{\\theta_{c, w_i}} \\right)^{w_i}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "#### Increasing numerical stability\n",
    "We can increase the numerical stability of the algorithm by taking logarithms of the posterior distributions, that is,\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\{0,1\\}}{\\operatorname{argmax}} \\ \\log \\left( \\textcolor{green}{p(C=c)}   \\prod_{i = 1}^k  \\left(\\textcolor{brown}{\\theta_{c, w_i}}\\right)^{w_i} \\right) \\\\\n",
    " = \\underset{c \\in \\{0,1\\}}{\\operatorname{argmax}} \\ \\left[ \\log( \\textcolor{green}{p(C=c)}) + \\sum_{i = 1}^k w_i \\ \\log \\left(\\textcolor{brown}{\\theta_{c, w_i}} \\right) \\right].\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part A: Estimate class priors\n",
    "\n",
    "Define a function called `estimate_log_class_priors()` that takes as input a data set with binary response variable (0s and 1s) in the left-most column and returns a numpy array containing the **the logarithm** of the empirical class priors $\\textcolor{green}{p(C=c)}$ for $c \\in \\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_log_class_priors(data):\n",
    "    \"\"\"\n",
    "    Given a data set with binary response variable (0s and 1s) in the\n",
    "    left-most column, calculate the logarithm of the empirical class priors,\n",
    "    that is, the logarithm of the proportions of 0s and 1s:\n",
    "        log(p(C=0)) and log(p(C=1))\n",
    "\n",
    "    :param data: a two-dimensional numpy-array with shape = [n_samples, 1 + n_features]\n",
    "                 the first column contains the binary response (coded as 0s and 1s).\n",
    "\n",
    "    :return log_class_priors: a numpy array of length two\n",
    "    \"\"\"\n",
    "\n",
    "    # get first column of array which contains the binary response variables\n",
    "    np_data_cols = data[:,0]\n",
    "    # can also do np_data_cols.sum to get number of 1s\n",
    "\n",
    "    # get number of zeros and ones\n",
    "    total = len(np_data_cols)\n",
    "    n_zeros = np.count_nonzero(np_data_cols==0)\n",
    "    n_ones = total - n_zeros\n",
    "\n",
    "    class_prior_zero, class_prior_one = n_zeros / total, n_ones / total\n",
    "\n",
    "    return np.array([np.log(class_prior_zero), np.log(class_prior_one)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e56af38a496339fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [-0.48939034 -0.94933059]\n"
     ]
    }
   ],
   "source": [
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "log_class_priors = estimate_log_class_priors(training_spam)\n",
    "# log_class_priors = estimate_log_class_priors(testing_spam)\n",
    "\n",
    "print(\"result\", log_class_priors)\n",
    "\n",
    "# Check length\n",
    "assert(len(log_class_priors) == 2)\n",
    "\n",
    "# Check whether the returned object is a numpy.ndarray\n",
    "assert(isinstance(log_class_priors, np.ndarray))\n",
    "\n",
    "# Check wehther the values of this numpy.array are floats.\n",
    "assert(log_class_priors.dtype == float)\n",
    "\n",
    "# Check wehther the values are both negative (the logarithm of a probability 0 < p < 1 should be negative).\n",
    "assert(np.all(log_class_priors < 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part B: Estimate class-conditional likelihoods\n",
    "Define a function called `estimate_log_class_conditional_likelihoods()` that takes as input a data set with binary response variable (0s and 1s) in the left-most column and returns **the logarithm** of the empirical class-conditional likelihoods $\\log \\left(\\textcolor{brown}{\\theta_{c, w_i}} \\right)$ for all words $w_i$ and both classes ($c \\in {0, 1}$). These parameters should be returned in a two-dimensional numpy-array with shape = `[num_classes, num_features]`.\n",
    "\n",
    "Assume a multinomial event model and use Laplace smoothing with $\\alpha = 1$. \n",
    "\n",
    "Hint: many `numpy`-functions contain an `axis` argument. If you specify `axis=0`, you can perform column-wise (that is, feature-wise!) computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_log_class_conditional_likelihoods(data, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Given a data set with binary response variable (0s and 1s) in the\n",
    "    left-most column and binary features (words), calculate the empirical\n",
    "    class-conditional likelihoods, that is,\n",
    "    log(P(w_i | c)) for all features w_i and both classes (c in {0, 1}).\n",
    "\n",
    "    Assume a multinomial feature distribution and use Laplace smoothing\n",
    "    if alpha > 0.\n",
    "\n",
    "    :param data: a two-dimensional numpy-array with shape = [n_samples, 1 + n_features]\n",
    "\n",
    "    :return theta:\n",
    "        a numpy array of shape = [2, n_features]. theta[j, i] corresponds to the\n",
    "        logarithm of the probability of feature i appearing in a sample belonging \n",
    "        to class j.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    # count zeros in each row\n",
    "    # two-dimensional array\n",
    "    # data = np.array([[1, 1, 0, 1, 0],\n",
    "    #                    [0, 0, 1, 1, 0],\n",
    "    #                    [0, 1, 0, 1, 1],\n",
    "    #                    [1, 1, 0, 1, 0],\n",
    "    #                    [1, 0, 0, 1, 1],\n",
    "    #                    [1, 1, 0, 1, 0]])\n",
    "                         # m, f, r, :\n",
    "    # np_spam = [np.where(data == 1, ) for col in range(len(data[0]))]\n",
    "    # print('sum:',np.sum(data, axis=0, where=data[:,0]==1)) #sum: [4 4 1 6 2]\n",
    "    # scam_rows = np.where(data[:,0]==1)[0]\n",
    "    # ham_rows = np.where(data[:,0]==0)[0]\n",
    "    # print('rows: scam:', scam_rows,'ham:' ,ham_rows) #rows: scam: [0 3 4 5] ham: [1 2]\n",
    "\n",
    "\n",
    "\n",
    "    # money: count of money in 1/total count of words in 1\n",
    "    # for each col in arr:\n",
    "    #  get count and rows that have 1s\n",
    "    #  for each row, check thos that have 1 as first element\n",
    "    spam_word_count, ham_word_count, result = 0, 0, [[],[]]\n",
    "    row_len, col_len = len(data), len(data[0])\n",
    "    spam_result, ham_result = [] , []\n",
    "\n",
    "    for col in range(1, col_len):\n",
    "        spam_count, ham_count = 0.0, 0.0\n",
    "        for row in range(row_len):\n",
    "            if data[row][col] == 1:\n",
    "                #  if spam\n",
    "                if data[row][0] == 1:\n",
    "                    spam_count += 1\n",
    "                    spam_word_count += 1\n",
    "                else:\n",
    "                    ham_count += 1\n",
    "                    ham_word_count += 1\n",
    "\n",
    "        # result[0].append(ham_count)\n",
    "        ham_result.append(ham_count)\n",
    "\n",
    "        # result[1].append(spam_count)\n",
    "        spam_result.append(spam_count)\n",
    "\n",
    "    print('spam_word:', spam_word_count)\n",
    "    print('ham_word:', ham_word_count)\n",
    "\n",
    "    # laplace smoothing: n(c,w) + alpha / n(w) + k*alpha where k = no of keywords\n",
    "    k = data.shape[1] - 1\n",
    "    print('k:', k)\n",
    "\n",
    "    spam_result = [np.log((count+alpha)/(spam_word_count + (k*alpha))) for count in spam_result]\n",
    "    ham_result = [np.log((count+alpha)/(ham_word_count + (k*alpha))) for count in ham_result]\n",
    "\n",
    "\n",
    "    return np.array([spam_result, ham_result])\n",
    "    # [[1 3 0 4 1]\n",
    "    #  [0 1 1 2 1]]\n",
    "\n",
    "    # n_zeros = np.count_nonzero(arr_2d==0, axis=1)\n",
    "    # # display the count of zeros\n",
    "    # print(n_zeros) # [1 2 0]\n",
    "    # # count zeros in each column\n",
    "    # n_zeros = np.count_nonzero(arr_2d==0, axis=0)\n",
    "    # # display the count of zeros\n",
    "    # # print(n_zeros) [1 1 1]\n",
    "    #\n",
    "    # # count zeros with np.where\n",
    "    # result = np.where(arr_2d==0)\n",
    "    #\n",
    "    # # show the result of np.where\n",
    "    # print(result) # (array([0, 1, 1], dtype=int64), array([2, 0, 1], dtype=int64))\n",
    "\n",
    "    # count of zeros\n",
    "    # n_zeros = result[0].size\n",
    "    # # display the count of zeros\n",
    "    # print(n_zeros) # 3\n",
    "\n",
    "    # The returned value from np.where() is a tuple of two arrays, the first one shows the row indexes of elements matching the condition (element equal to zero) and the second array gives the column indexes for those elements. Counting the indexes in any of these arrays gives the count of zeros in the array.\n",
    "\n",
    "    # return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-851fa744923a9bba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_word: 5028\n",
      "ham_word: 4917\n",
      "k: 54\n",
      "[[-3.54302758 -3.73766962 -3.08672279 -6.58755001 -2.9961259  -3.4520558\n",
      "  -3.47086513 -3.59181774 -3.77986997 -3.31852441 -3.77986997 -3.04039872\n",
      "  -3.70514643 -4.64163987 -4.52612698 -3.13529746 -3.39766173 -3.62080528\n",
      "  -2.68125768 -4.05612335 -2.78088753 -5.58902118 -3.68927308 -3.48360416\n",
      "  -6.04855351 -6.33623559 -7.84031298 -6.74170069 -6.92402225 -7.1471658\n",
      "  -7.84031298 -8.53346016 -5.96851081 -8.53346016 -5.76087144 -5.20125565\n",
      "  -5.35540633 -6.58755001 -5.70024682 -4.56316825 -8.53346016 -7.43484788\n",
      "  -5.31458434 -6.92402225 -3.86063133 -5.96851081 -6.74170069 -7.1471658\n",
      "  -4.37457708 -3.02407183 -4.94994123 -2.73134179 -3.03220195 -3.86063133]\n",
      " [-3.83854747 -4.40050244 -3.37557787 -7.81822913 -3.56973388 -4.35249322\n",
      "  -5.94642695 -4.79780424 -4.52239226 -3.88640349 -4.87379015 -2.9354272\n",
      "  -4.11692715 -5.1791718  -6.02646966 -4.40050244 -4.33698904 -4.11692715\n",
      "  -2.67073465 -5.94642695 -3.16426878 -6.71961684 -5.67816296 -5.94642695\n",
      "  -3.06463893 -3.36388183 -3.41150988 -3.94702811 -4.11692715 -4.0005168\n",
      "  -4.38424192 -4.6401753  -4.2918686  -4.61955601 -3.95749941 -3.87664732\n",
      "  -3.34089231 -6.02646966 -4.26288106 -4.40050244 -5.1791718  -4.18064297\n",
      "  -4.33698904 -4.38424192 -3.31287927 -3.85741596 -6.02646966 -4.90045839\n",
      "  -3.78398849 -2.68243069 -4.01156664 -3.32959276 -4.35249322 -4.54108439]]\n"
     ]
    }
   ],
   "source": [
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "log_class_conditional_likelihoods = estimate_log_class_conditional_likelihoods(training_spam, alpha=1.0)\n",
    "print(log_class_conditional_likelihoods)\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(log_class_conditional_likelihoods, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(log_class_conditional_likelihoods.shape == (2, 54))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(log_class_conditional_likelihoods.dtype == float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part  C: Classify e-mails\n",
    "\n",
    "Having calculated the log class priors and the log class-conditional likelihoods for a given training set, define a function called `predict()`that takes a data set of new messages as input and predicts for each message whether it is spam or not. Note that the input should **not** contain a response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(new_data, log_class_priors, log_class_conditional_likelihoods):\n",
    "    \"\"\"\n",
    "    Given a new data set with binary features, predict the corresponding\n",
    "    response for each instance (row) of the new_data set.\n",
    "\n",
    "    :param new_data: a two-dimensional numpy-array with shape = [n_test_samples, n_features].\n",
    "    :param log_class_priors: a numpy array of length 2.\n",
    "    :param log_class_conditional_likelihoods: a numpy array of shape = [2, n_features].\n",
    "        theta[j, i] corresponds to the logarithm of the probability of feature i appearing\n",
    "        in a sample belonging to class j.\n",
    "    :return class_predictions: a numpy array containing the class predictions for each row\n",
    "        of new_data.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE...\n",
    "    predictions = []\n",
    "    # new_data = np.array([[1, 0, 1, 0],\n",
    "    #                      [0, 1, 1, 0],\n",
    "    #                      [1, 0, 1, 1],\n",
    "    #                      [1, 0, 1, 0],\n",
    "    #                      [0, 0, 1, 1],\n",
    "    #                      [1, 0, 1, 0]])\n",
    "    # m, f, r, :\n",
    "    # for each row\n",
    "    for row in range(len(new_data)):\n",
    "    #   check probability of spam and ham\n",
    "            # spam => multiply log_class_priors(spam) by the logs of all features (conditional likelihoods) that are 1 for spam i.e log_class_conditional_likelihoods[1][feature where feature =1]\n",
    "    #STEPS:\n",
    "    #   get cols that the keywords are present i.e 1\n",
    "        cols_with_keywords = np.where(new_data[row] == 1)[0]\n",
    "        # print('colswithkeyword',cols_with_keywords)\n",
    "        # print('logs for cols:', [log_class_conditional_likelihoods[0][i] for i in cols_with_keywords])\n",
    "    # row_product_numerator = log_class_priors*log_class_conditionals\n",
    "        ham_conditional_likelihoods_product = np.product([log_class_conditional_likelihoods[0][i] for i in cols_with_keywords])\n",
    "\n",
    "        ham_numerator = log_class_priors[1] * ham_conditional_likelihoods_product\n",
    "        #### SPAM CALCULATION ###\n",
    "        # row_product_numerator = log_class_priors*log_class_conditionals\n",
    "        spam_conditional_likelihoods_product = np.product([log_class_conditional_likelihoods[1][i] for i in cols_with_keywords])\n",
    "        spam_numerator = log_class_priors[1] * spam_conditional_likelihoods_product\n",
    "\n",
    "        # spam_numerator + ham_numerator/denominator = 1\n",
    "        denominator = spam_numerator + ham_numerator\n",
    "        spam_percentage, ham_percentage = spam_numerator/denominator, ham_numerator/denominator\n",
    "        print(f'for row {row}, spam_prob: {spam_percentage}, ham_prob: {ham_percentage}')\n",
    "\n",
    "        predictions.append(0 if ham_percentage > spam_percentage else 1)\n",
    "\n",
    "    #   classify dataset depending on which probability is greater\n",
    "\n",
    "    p= np.array(predictions)\n",
    "    print('p_shape',p.shape)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c8adaa150209180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for row 0, spam_prob: 0.921856545773183, ham_prob: 0.07814345422681714\n",
      "for row 1, spam_prob: 0.8326396908763123, ham_prob: 0.16736030912368763\n",
      "for row 2, spam_prob: 0.37844053181868254, ham_prob: 0.6215594681813175\n",
      "for row 3, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 4, spam_prob: 0.22897130008845853, ham_prob: 0.7710286999115415\n",
      "for row 5, spam_prob: 0.000980470534113507, ham_prob: 0.9990195294658865\n",
      "for row 6, spam_prob: 0.3456989735706289, ham_prob: 0.6543010264293712\n",
      "for row 7, spam_prob: 0.17881209850016205, ham_prob: 0.8211879014998379\n",
      "for row 8, spam_prob: 0.1921101587431381, ham_prob: 0.8078898412568619\n",
      "for row 9, spam_prob: 0.3362859888826234, ham_prob: 0.6637140111173766\n",
      "for row 10, spam_prob: 0.16217358448529312, ham_prob: 0.8378264155147068\n",
      "for row 11, spam_prob: 0.49901690485244005, ham_prob: 0.50098309514756\n",
      "for row 12, spam_prob: 0.540723691925808, ham_prob: 0.4592763080741919\n",
      "for row 13, spam_prob: 0.05981721808700061, ham_prob: 0.9401827819129994\n",
      "for row 14, spam_prob: 0.1560885423160036, ham_prob: 0.8439114576839963\n",
      "for row 15, spam_prob: 0.8710122555073725, ham_prob: 0.12898774449262743\n",
      "for row 16, spam_prob: 0.744495186577781, ham_prob: 0.255504813422219\n",
      "for row 17, spam_prob: 0.025064400701141916, ham_prob: 0.9749355992988581\n",
      "for row 18, spam_prob: 0.882824941533466, ham_prob: 0.117175058466534\n",
      "for row 19, spam_prob: 0.8998739223875645, ham_prob: 0.1001260776124356\n",
      "for row 20, spam_prob: 0.06426180223759444, ham_prob: 0.9357381977624055\n",
      "for row 21, spam_prob: 0.6129968516347891, ham_prob: 0.38700314836521077\n",
      "for row 22, spam_prob: 0.5758448933950351, ham_prob: 0.4241551066049649\n",
      "for row 23, spam_prob: 0.46814462718634536, ham_prob: 0.5318553728136547\n",
      "for row 24, spam_prob: 0.9380745334864676, ham_prob: 0.061925466513532354\n",
      "for row 25, spam_prob: 0.713109863210444, ham_prob: 0.2868901367895561\n",
      "for row 26, spam_prob: 0.08729719042598337, ham_prob: 0.9127028095740166\n",
      "for row 27, spam_prob: 0.4170128643586112, ham_prob: 0.5829871356413889\n",
      "for row 28, spam_prob: 0.8672739722950639, ham_prob: 0.13272602770493605\n",
      "for row 29, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 30, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 31, spam_prob: 0.0006807338376286749, ham_prob: 0.9993192661623713\n",
      "for row 32, spam_prob: 0.6623470235628477, ham_prob: 0.3376529764371523\n",
      "for row 33, spam_prob: 0.6303206904357359, ham_prob: 0.36967930956426404\n",
      "for row 34, spam_prob: 0.9381797214078446, ham_prob: 0.06182027859215544\n",
      "for row 35, spam_prob: 0.6294186143990346, ham_prob: 0.3705813856009654\n",
      "for row 36, spam_prob: 0.9335509063956274, ham_prob: 0.0664490936043726\n",
      "for row 37, spam_prob: 0.4487070320245455, ham_prob: 0.5512929679754545\n",
      "for row 38, spam_prob: 0.19090808823657565, ham_prob: 0.8090919117634243\n",
      "for row 39, spam_prob: 0.06597653836318428, ham_prob: 0.9340234616368157\n",
      "for row 40, spam_prob: 0.877139292339521, ham_prob: 0.12286070766047893\n",
      "for row 41, spam_prob: 0.49901690485244005, ham_prob: 0.50098309514756\n",
      "for row 42, spam_prob: 0.06401505051826759, ham_prob: 0.9359849494817325\n",
      "for row 43, spam_prob: 0.9940213530490061, ham_prob: 0.005978646950993851\n",
      "for row 44, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 45, spam_prob: 0.9771796857620226, ham_prob: 0.022820314237977292\n",
      "for row 46, spam_prob: 0.39587504380800503, ham_prob: 0.604124956191995\n",
      "for row 47, spam_prob: 0.8824515699710636, ham_prob: 0.11754843002893654\n",
      "for row 48, spam_prob: 0.3818195287548396, ham_prob: 0.6181804712451604\n",
      "for row 49, spam_prob: 0.03172287279349172, ham_prob: 0.9682771272065083\n",
      "for row 50, spam_prob: 0.13809922275294406, ham_prob: 0.8619007772470559\n",
      "for row 51, spam_prob: 0.40495098422947495, ham_prob: 0.595049015770525\n",
      "for row 52, spam_prob: 0.9878090621311688, ham_prob: 0.01219093786883114\n",
      "for row 53, spam_prob: 0.7280648449224679, ham_prob: 0.271935155077532\n",
      "for row 54, spam_prob: 0.12543528356269915, ham_prob: 0.8745647164373009\n",
      "for row 55, spam_prob: 0.9619926594282269, ham_prob: 0.038007340571773254\n",
      "for row 56, spam_prob: 0.5521158841924344, ham_prob: 0.4478841158075656\n",
      "for row 57, spam_prob: 0.7880738079584533, ham_prob: 0.21192619204154678\n",
      "for row 58, spam_prob: 0.36797583759785396, ham_prob: 0.6320241624021461\n",
      "for row 59, spam_prob: 0.37482650428619124, ham_prob: 0.6251734957138088\n",
      "for row 60, spam_prob: 0.8039803229641587, ham_prob: 0.1960196770358414\n",
      "for row 61, spam_prob: 0.12486549978950809, ham_prob: 0.875134500210492\n",
      "for row 62, spam_prob: 0.36351076007528343, ham_prob: 0.6364892399247166\n",
      "for row 63, spam_prob: 0.5759141452456984, ham_prob: 0.4240858547543015\n",
      "for row 64, spam_prob: 0.9776672224835158, ham_prob: 0.02233277751648412\n",
      "for row 65, spam_prob: 0.675415051019147, ham_prob: 0.324584948980853\n",
      "for row 66, spam_prob: 0.7462406796990967, ham_prob: 0.2537593203009032\n",
      "for row 67, spam_prob: 0.9701003295831707, ham_prob: 0.029899670416829408\n",
      "for row 68, spam_prob: 0.7419095688034288, ham_prob: 0.2580904311965712\n",
      "for row 69, spam_prob: 0.340638814028202, ham_prob: 0.659361185971798\n",
      "for row 70, spam_prob: 0.6507093491878917, ham_prob: 0.3492906508121083\n",
      "for row 71, spam_prob: 0.29701992470740335, ham_prob: 0.7029800752925967\n",
      "for row 72, spam_prob: 0.24956923076777882, ham_prob: 0.7504307692322212\n",
      "for row 73, spam_prob: 0.8996208420048648, ham_prob: 0.10037915799513521\n",
      "for row 74, spam_prob: 0.04508889005458268, ham_prob: 0.9549111099454173\n",
      "for row 75, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 76, spam_prob: 0.9089434179812608, ham_prob: 0.09105658201873924\n",
      "for row 77, spam_prob: 0.0007992051893289138, ham_prob: 0.999200794810671\n",
      "for row 78, spam_prob: 0.05260448794852223, ham_prob: 0.9473955120514778\n",
      "for row 79, spam_prob: 0.5748664642682217, ham_prob: 0.42513353573177826\n",
      "for row 80, spam_prob: 0.3745577228556422, ham_prob: 0.6254422771443578\n",
      "for row 81, spam_prob: 0.04295870326346827, ham_prob: 0.9570412967365318\n",
      "for row 82, spam_prob: 0.3678734720442276, ham_prob: 0.6321265279557724\n",
      "for row 83, spam_prob: 0.00016127988999103731, ham_prob: 0.999838720110009\n",
      "for row 84, spam_prob: 0.05041472706844717, ham_prob: 0.9495852729315529\n",
      "for row 85, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 86, spam_prob: 0.9900819914536046, ham_prob: 0.009918008546395386\n",
      "for row 87, spam_prob: 0.9591630366698113, ham_prob: 0.04083696333018868\n",
      "for row 88, spam_prob: 0.17513763281885875, ham_prob: 0.8248623671811411\n",
      "for row 89, spam_prob: 0.4640450716430132, ham_prob: 0.535954928356987\n",
      "for row 90, spam_prob: 0.43304018414926393, ham_prob: 0.5669598158507361\n",
      "for row 91, spam_prob: 0.41953257664101, ham_prob: 0.5804674233589899\n",
      "for row 92, spam_prob: 0.00028096619990053775, ham_prob: 0.9997190338000994\n",
      "for row 93, spam_prob: 0.1317210192842595, ham_prob: 0.8682789807157405\n",
      "for row 94, spam_prob: 0.7082454851056247, ham_prob: 0.2917545148943753\n",
      "for row 95, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 96, spam_prob: 0.17308787831802494, ham_prob: 0.826912121681975\n",
      "for row 97, spam_prob: 0.505243036687721, ham_prob: 0.4947569633122792\n",
      "for row 98, spam_prob: 0.7136253118391067, ham_prob: 0.28637468816089323\n",
      "for row 99, spam_prob: 0.46448680223726857, ham_prob: 0.5355131977627314\n",
      "for row 100, spam_prob: 0.9163686295445748, ham_prob: 0.08363137045542529\n",
      "for row 101, spam_prob: 0.3206314627477209, ham_prob: 0.6793685372522792\n",
      "for row 102, spam_prob: 0.4490386338735185, ham_prob: 0.5509613661264814\n",
      "for row 103, spam_prob: 0.3327757030542366, ham_prob: 0.6672242969457635\n",
      "for row 104, spam_prob: 0.5810770308125873, ham_prob: 0.4189229691874127\n",
      "for row 105, spam_prob: 0.7160876752545821, ham_prob: 0.28391232474541794\n",
      "for row 106, spam_prob: 0.540723691925808, ham_prob: 0.4592763080741919\n",
      "for row 107, spam_prob: 0.2061624676336973, ham_prob: 0.7938375323663027\n",
      "for row 108, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 109, spam_prob: 0.8232297104271564, ham_prob: 0.17677028957284352\n",
      "for row 110, spam_prob: 0.5138190074172659, ham_prob: 0.4861809925827342\n",
      "for row 111, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 112, spam_prob: 0.6817558124853836, ham_prob: 0.31824418751461636\n",
      "for row 113, spam_prob: 0.027270130634371635, ham_prob: 0.9727298693656283\n",
      "for row 114, spam_prob: 0.10401230261884073, ham_prob: 0.8959876973811594\n",
      "for row 115, spam_prob: 0.12670251866896176, ham_prob: 0.8732974813310382\n",
      "for row 116, spam_prob: 0.13711317775561463, ham_prob: 0.8628868222443854\n",
      "for row 117, spam_prob: 0.16405780256311495, ham_prob: 0.8359421974368851\n",
      "for row 118, spam_prob: 0.38672359505815557, ham_prob: 0.6132764049418444\n",
      "for row 119, spam_prob: 0.49901690485244005, ham_prob: 0.50098309514756\n",
      "for row 120, spam_prob: 0.2831363907769899, ham_prob: 0.7168636092230101\n",
      "for row 121, spam_prob: 0.7733550567957574, ham_prob: 0.2266449432042425\n",
      "for row 122, spam_prob: 0.03295913282065389, ham_prob: 0.9670408671793461\n",
      "for row 123, spam_prob: 0.9569896161123315, ham_prob: 0.04301038388766849\n",
      "for row 124, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 125, spam_prob: 0.5483793239420881, ham_prob: 0.451620676057912\n",
      "for row 126, spam_prob: 0.43517350387257353, ham_prob: 0.5648264961274264\n",
      "for row 127, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 128, spam_prob: 0.0006508016984868117, ham_prob: 0.9993491983015131\n",
      "for row 129, spam_prob: 0.8234455166092806, ham_prob: 0.17655448339071944\n",
      "for row 130, spam_prob: 0.21197213595962044, ham_prob: 0.7880278640403795\n",
      "for row 131, spam_prob: 0.59311461968038, ham_prob: 0.40688538031961996\n",
      "for row 132, spam_prob: 0.38224381258391327, ham_prob: 0.6177561874160867\n",
      "for row 133, spam_prob: 0.03422504867185343, ham_prob: 0.9657749513281466\n",
      "for row 134, spam_prob: 0.43236094080966364, ham_prob: 0.5676390591903363\n",
      "for row 135, spam_prob: 0.7617657904346994, ham_prob: 0.23823420956530053\n",
      "for row 136, spam_prob: 0.18068667897857993, ham_prob: 0.8193133210214202\n",
      "for row 137, spam_prob: 0.3362859888826234, ham_prob: 0.6637140111173766\n",
      "for row 138, spam_prob: 0.6525708875318742, ham_prob: 0.34742911246812574\n",
      "for row 139, spam_prob: 0.30774065465303047, ham_prob: 0.6922593453469695\n",
      "for row 140, spam_prob: 0.6028060572586217, ham_prob: 0.39719394274137837\n",
      "for row 141, spam_prob: 0.9288357544728559, ham_prob: 0.07116424552714405\n",
      "for row 142, spam_prob: 0.020028857330929246, ham_prob: 0.9799711426690708\n",
      "for row 143, spam_prob: 0.09940860616366819, ham_prob: 0.9005913938363319\n",
      "for row 144, spam_prob: 0.46182119991116616, ham_prob: 0.5381788000888339\n",
      "for row 145, spam_prob: 0.695012639896132, ham_prob: 0.30498736010386795\n",
      "for row 146, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 147, spam_prob: 0.46182119991116616, ham_prob: 0.5381788000888339\n",
      "for row 148, spam_prob: 0.5033236426661878, ham_prob: 0.49667635733381216\n",
      "for row 149, spam_prob: 0.00018924714673461, ham_prob: 0.9998107528532655\n",
      "for row 150, spam_prob: 0.4568287860189612, ham_prob: 0.5431712139810388\n",
      "for row 151, spam_prob: 0.8528495996609985, ham_prob: 0.14715040033900156\n",
      "for row 152, spam_prob: 0.08924312925723084, ham_prob: 0.9107568707427691\n",
      "for row 153, spam_prob: 0.13686933250125433, ham_prob: 0.8631306674987457\n",
      "for row 154, spam_prob: 0.8160274087350036, ham_prob: 0.18397259126499635\n",
      "for row 155, spam_prob: 0.6193238349554872, ham_prob: 0.3806761650445128\n",
      "for row 156, spam_prob: 0.5195340927526872, ham_prob: 0.4804659072473128\n",
      "for row 157, spam_prob: 0.2620003789641309, ham_prob: 0.737999621035869\n",
      "for row 158, spam_prob: 0.8547696132308618, ham_prob: 0.1452303867691383\n",
      "for row 159, spam_prob: 0.00015926377339993937, ham_prob: 0.9998407362266001\n",
      "for row 160, spam_prob: 0.8229201624599962, ham_prob: 0.17707983754000386\n",
      "for row 161, spam_prob: 0.2675874285855691, ham_prob: 0.732412571414431\n",
      "for row 162, spam_prob: 0.9717458649837001, ham_prob: 0.028254135016299947\n",
      "for row 163, spam_prob: 0.8389120319771042, ham_prob: 0.16108796802289574\n",
      "for row 164, spam_prob: 0.9465049966961909, ham_prob: 0.05349500330380903\n",
      "for row 165, spam_prob: 0.7874789491403942, ham_prob: 0.21252105085960585\n",
      "for row 166, spam_prob: 0.8520461042138155, ham_prob: 0.1479538957861845\n",
      "for row 167, spam_prob: 0.05771696979284408, ham_prob: 0.9422830302071559\n",
      "for row 168, spam_prob: 0.3599196127850505, ham_prob: 0.6400803872149495\n",
      "for row 169, spam_prob: 0.9133992479274462, ham_prob: 0.08660075207255379\n",
      "for row 170, spam_prob: 0.6240155308503176, ham_prob: 0.37598446914968237\n",
      "for row 171, spam_prob: 0.16420851736106432, ham_prob: 0.8357914826389355\n",
      "for row 172, spam_prob: 0.6220944085920713, ham_prob: 0.3779055914079287\n",
      "for row 173, spam_prob: 0.8760487545803681, ham_prob: 0.12395124541963182\n",
      "for row 174, spam_prob: 0.09943647461245492, ham_prob: 0.900563525387545\n",
      "for row 175, spam_prob: 0.61956688684844, ham_prob: 0.38043311315156014\n",
      "for row 176, spam_prob: 0.5396637256492707, ham_prob: 0.4603362743507293\n",
      "for row 177, spam_prob: 0.1436933210994054, ham_prob: 0.8563066789005946\n",
      "for row 178, spam_prob: 0.07117728832342152, ham_prob: 0.9288227116765786\n",
      "for row 179, spam_prob: 0.3575584779827215, ham_prob: 0.6424415220172784\n",
      "for row 180, spam_prob: 0.11578449183870228, ham_prob: 0.8842155081612978\n",
      "for row 181, spam_prob: 0.9285913813357565, ham_prob: 0.07140861866424346\n",
      "for row 182, spam_prob: 0.824043257216841, ham_prob: 0.17595674278315906\n",
      "for row 183, spam_prob: 0.31928386320243946, ham_prob: 0.6807161367975605\n",
      "for row 184, spam_prob: 0.9642141766634712, ham_prob: 0.03578582333652873\n",
      "for row 185, spam_prob: 0.8096019625335016, ham_prob: 0.1903980374664985\n",
      "for row 186, spam_prob: 0.9818396095514736, ham_prob: 0.018160390448526294\n",
      "for row 187, spam_prob: 0.09476788841944395, ham_prob: 0.905232111580556\n",
      "for row 188, spam_prob: 0.002608661654201338, ham_prob: 0.9973913383457986\n",
      "for row 189, spam_prob: 0.21101061070382757, ham_prob: 0.7889893892961725\n",
      "for row 190, spam_prob: 0.9153299220790799, ham_prob: 0.08467007792092007\n",
      "for row 191, spam_prob: 0.9701003295831707, ham_prob: 0.029899670416829408\n",
      "for row 192, spam_prob: 0.20849687371023043, ham_prob: 0.7915031262897696\n",
      "for row 193, spam_prob: 0.46182119991116616, ham_prob: 0.5381788000888339\n",
      "for row 194, spam_prob: 0.7186895218039167, ham_prob: 0.28131047819608324\n",
      "for row 195, spam_prob: 0.1767978728615688, ham_prob: 0.8232021271384312\n",
      "for row 196, spam_prob: 0.3247371277388511, ham_prob: 0.6752628722611489\n",
      "for row 197, spam_prob: 0.4125355205364701, ham_prob: 0.58746447946353\n",
      "for row 198, spam_prob: 0.0003712761749120996, ham_prob: 0.9996287238250879\n",
      "for row 199, spam_prob: 0.06985097093532476, ham_prob: 0.9301490290646752\n",
      "for row 200, spam_prob: 0.9418825198203997, ham_prob: 0.058117480179600264\n",
      "for row 201, spam_prob: 0.10097655865809255, ham_prob: 0.8990234413419075\n",
      "for row 202, spam_prob: 0.05385934572523447, ham_prob: 0.9461406542747656\n",
      "for row 203, spam_prob: 0.4257211610937418, ham_prob: 0.5742788389062583\n",
      "for row 204, spam_prob: 0.9045349581479049, ham_prob: 0.09546504185209517\n",
      "for row 205, spam_prob: 0.08417529706214877, ham_prob: 0.9158247029378512\n",
      "for row 206, spam_prob: 0.31364157922493685, ham_prob: 0.6863584207750631\n",
      "for row 207, spam_prob: 0.547280777190713, ham_prob: 0.452719222809287\n",
      "for row 208, spam_prob: 0.7695931090263998, ham_prob: 0.23040689097360031\n",
      "for row 209, spam_prob: 0.12767205448379434, ham_prob: 0.8723279455162056\n",
      "for row 210, spam_prob: 0.893481790937496, ham_prob: 0.10651820906250392\n",
      "for row 211, spam_prob: 0.8966098407566571, ham_prob: 0.10339015924334287\n",
      "for row 212, spam_prob: 0.03874961157080655, ham_prob: 0.9612503884291934\n",
      "for row 213, spam_prob: 0.7744999114945335, ham_prob: 0.2255000885054665\n",
      "for row 214, spam_prob: 0.7437122854349149, ham_prob: 0.25628771456508515\n",
      "for row 215, spam_prob: 0.5263217112916566, ham_prob: 0.47367828870834333\n",
      "for row 216, spam_prob: 0.4671945769389214, ham_prob: 0.5328054230610785\n",
      "for row 217, spam_prob: 0.4443855138865319, ham_prob: 0.5556144861134681\n",
      "for row 218, spam_prob: 0.540723691925808, ham_prob: 0.4592763080741919\n",
      "for row 219, spam_prob: 0.03236782059823614, ham_prob: 0.9676321794017638\n",
      "for row 220, spam_prob: 0.5544354974155866, ham_prob: 0.4455645025844133\n",
      "for row 221, spam_prob: 0.4075281446779004, ham_prob: 0.5924718553220996\n",
      "for row 222, spam_prob: 0.5346080618771599, ham_prob: 0.46539193812283997\n",
      "for row 223, spam_prob: 0.9856690120884101, ham_prob: 0.014330987911589908\n",
      "for row 224, spam_prob: 0.12979427537462063, ham_prob: 0.8702057246253794\n",
      "for row 225, spam_prob: 0.4700656279546415, ham_prob: 0.5299343720453584\n",
      "for row 226, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 227, spam_prob: 0.14476862722297196, ham_prob: 0.8552313727770281\n",
      "for row 228, spam_prob: 0.9583965247823016, ham_prob: 0.04160347521769826\n",
      "for row 229, spam_prob: 0.25811700865841175, ham_prob: 0.7418829913415883\n",
      "for row 230, spam_prob: 0.3252223739293173, ham_prob: 0.6747776260706826\n",
      "for row 231, spam_prob: 0.98432070732991, ham_prob: 0.0156792926700901\n",
      "for row 232, spam_prob: 0.9290543582050786, ham_prob: 0.07094564179492141\n",
      "for row 233, spam_prob: 0.3863151137169459, ham_prob: 0.6136848862830541\n",
      "for row 234, spam_prob: 0.5847079935498442, ham_prob: 0.41529200645015585\n",
      "for row 235, spam_prob: 0.3478323546145812, ham_prob: 0.6521676453854188\n",
      "for row 236, spam_prob: 0.692528878126803, ham_prob: 0.30747112187319686\n",
      "for row 237, spam_prob: 0.6753887286527823, ham_prob: 0.32461127134721773\n",
      "for row 238, spam_prob: 0.5818034673409683, ham_prob: 0.4181965326590316\n",
      "for row 239, spam_prob: 0.4700656279546415, ham_prob: 0.5299343720453584\n",
      "for row 240, spam_prob: 0.7380843633452057, ham_prob: 0.2619156366547943\n",
      "for row 241, spam_prob: 0.6414351883870574, ham_prob: 0.3585648116129427\n",
      "for row 242, spam_prob: 0.5273669808905359, ham_prob: 0.47263301910946426\n",
      "for row 243, spam_prob: 0.6660850574396519, ham_prob: 0.3339149425603482\n",
      "for row 244, spam_prob: 0.49901690485244005, ham_prob: 0.50098309514756\n",
      "for row 245, spam_prob: 0.5221270045977938, ham_prob: 0.47787299540220607\n",
      "for row 246, spam_prob: 0.7689671453237527, ham_prob: 0.23103285467624737\n",
      "for row 247, spam_prob: 0.952647766210696, ham_prob: 0.047352233789303935\n",
      "for row 248, spam_prob: 0.4408068839097438, ham_prob: 0.5591931160902561\n",
      "for row 249, spam_prob: 0.009723256001755828, ham_prob: 0.9902767439982442\n",
      "for row 250, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 251, spam_prob: 0.6500185054302005, ham_prob: 0.34998149456979954\n",
      "for row 252, spam_prob: 0.09769796139754962, ham_prob: 0.9023020386024504\n",
      "for row 253, spam_prob: 0.9353143973587718, ham_prob: 0.06468560264122829\n",
      "for row 254, spam_prob: 0.810134990248603, ham_prob: 0.18986500975139703\n",
      "for row 255, spam_prob: 0.3515256305957503, ham_prob: 0.6484743694042496\n",
      "for row 256, spam_prob: 0.08449832817877487, ham_prob: 0.9155016718212251\n",
      "for row 257, spam_prob: 0.9367420620228482, ham_prob: 0.06325793797715189\n",
      "for row 258, spam_prob: 0.034488999548313366, ham_prob: 0.9655110004516866\n",
      "for row 259, spam_prob: 0.53502637988385, ham_prob: 0.46497362011615\n",
      "for row 260, spam_prob: 0.8941536580548513, ham_prob: 0.10584634194514869\n",
      "for row 261, spam_prob: 0.10220855249214675, ham_prob: 0.8977914475078532\n",
      "for row 262, spam_prob: 0.12137347893038623, ham_prob: 0.8786265210696138\n",
      "for row 263, spam_prob: 0.9716436566272791, ham_prob: 0.028356343372720846\n",
      "for row 264, spam_prob: 0.5225057350570791, ham_prob: 0.47749426494292097\n",
      "for row 265, spam_prob: 0.8988455032816594, ham_prob: 0.10115449671834069\n",
      "for row 266, spam_prob: 0.0012339975406949917, ham_prob: 0.9987660024593049\n",
      "for row 267, spam_prob: 0.9898797931399829, ham_prob: 0.010120206860017123\n",
      "for row 268, spam_prob: 0.48874005775878515, ham_prob: 0.5112599422412148\n",
      "for row 269, spam_prob: 0.6018641429873022, ham_prob: 0.3981358570126979\n",
      "for row 270, spam_prob: 0.16164666879962408, ham_prob: 0.8383533312003758\n",
      "for row 271, spam_prob: 0.2998318985802237, ham_prob: 0.7001681014197763\n",
      "for row 272, spam_prob: 0.18252542447977071, ham_prob: 0.8174745755202293\n",
      "for row 273, spam_prob: 0.9559270631564742, ham_prob: 0.04407293684352567\n",
      "for row 274, spam_prob: 0.7093029406401834, ham_prob: 0.29069705935981666\n",
      "for row 275, spam_prob: 0.709528921644204, ham_prob: 0.290471078355796\n",
      "for row 276, spam_prob: 0.5255454715534486, ham_prob: 0.47445452844655156\n",
      "for row 277, spam_prob: 0.9936186314358871, ham_prob: 0.006381368564112914\n",
      "for row 278, spam_prob: 0.7532338431399158, ham_prob: 0.2467661568600841\n",
      "for row 279, spam_prob: 0.6625077160920928, ham_prob: 0.33749228390790714\n",
      "for row 280, spam_prob: 0.4260356438737102, ham_prob: 0.5739643561262898\n",
      "for row 281, spam_prob: 0.8816320667820311, ham_prob: 0.11836793321796901\n",
      "for row 282, spam_prob: 0.00031903438384963046, ham_prob: 0.9996809656161504\n",
      "for row 283, spam_prob: 0.947273652506194, ham_prob: 0.05272634749380607\n",
      "for row 284, spam_prob: 0.8843341538972822, ham_prob: 0.11566584610271774\n",
      "for row 285, spam_prob: 0.12511274183146065, ham_prob: 0.8748872581685393\n",
      "for row 286, spam_prob: 0.9381427381321042, ham_prob: 0.061857261867895676\n",
      "for row 287, spam_prob: 0.7678452752736085, ham_prob: 0.23215472472639162\n",
      "for row 288, spam_prob: 0.3234181011973824, ham_prob: 0.6765818988026175\n",
      "for row 289, spam_prob: 0.1870812345422632, ham_prob: 0.8129187654577368\n",
      "for row 290, spam_prob: 0.025320237226060784, ham_prob: 0.9746797627739392\n",
      "for row 291, spam_prob: 0.09669456831579451, ham_prob: 0.9033054316842054\n",
      "for row 292, spam_prob: 0.8816998258252688, ham_prob: 0.11830017417473122\n",
      "for row 293, spam_prob: 0.891620588157786, ham_prob: 0.10837941184221403\n",
      "for row 294, spam_prob: 0.9885943143221491, ham_prob: 0.01140568567785083\n",
      "for row 295, spam_prob: 0.9599318929047644, ham_prob: 0.04006810709523555\n",
      "for row 296, spam_prob: 0.1317210192842595, ham_prob: 0.8682789807157405\n",
      "for row 297, spam_prob: 0.24468117808551562, ham_prob: 0.7553188219144843\n",
      "for row 298, spam_prob: 0.8361274671627452, ham_prob: 0.16387253283725475\n",
      "for row 299, spam_prob: 0.6514281996241216, ham_prob: 0.34857180037587826\n",
      "for row 300, spam_prob: 0.9398309174249868, ham_prob: 0.06016908257501323\n",
      "for row 301, spam_prob: 0.43810191853465164, ham_prob: 0.5618980814653484\n",
      "for row 302, spam_prob: 0.6034002477357562, ham_prob: 0.39659975226424377\n",
      "for row 303, spam_prob: 0.9585940794422302, ham_prob: 0.04140592055776972\n",
      "for row 304, spam_prob: 0.7456837955846575, ham_prob: 0.2543162044153425\n",
      "for row 305, spam_prob: 0.5401471760298415, ham_prob: 0.45985282397015853\n",
      "for row 306, spam_prob: 0.07473859411324489, ham_prob: 0.9252614058867551\n",
      "for row 307, spam_prob: 0.6919526741221793, ham_prob: 0.30804732587782063\n",
      "for row 308, spam_prob: 0.09162505429947497, ham_prob: 0.908374945700525\n",
      "for row 309, spam_prob: 0.25056469085005795, ham_prob: 0.749435309149942\n",
      "for row 310, spam_prob: 0.35584471932422906, ham_prob: 0.644155280675771\n",
      "for row 311, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 312, spam_prob: 0.2033265612849558, ham_prob: 0.7966734387150441\n",
      "for row 313, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 314, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 315, spam_prob: 0.07726521711277168, ham_prob: 0.9227347828872283\n",
      "for row 316, spam_prob: 0.9850190732907648, ham_prob: 0.014980926709235133\n",
      "for row 317, spam_prob: 0.6045305155285926, ham_prob: 0.3954694844714073\n",
      "for row 318, spam_prob: 0.3844135215895042, ham_prob: 0.6155864784104957\n",
      "for row 319, spam_prob: 0.7646716305803944, ham_prob: 0.23532836941960555\n",
      "for row 320, spam_prob: 0.24929789595646823, ham_prob: 0.7507021040435317\n",
      "for row 321, spam_prob: 0.4286072944158132, ham_prob: 0.5713927055841868\n",
      "for row 322, spam_prob: 0.03875369091003052, ham_prob: 0.9612463090899696\n",
      "for row 323, spam_prob: 0.27848185229660366, ham_prob: 0.7215181477033963\n",
      "for row 324, spam_prob: 0.47190740964239175, ham_prob: 0.5280925903576081\n",
      "for row 325, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 326, spam_prob: 0.3496170699684366, ham_prob: 0.6503829300315633\n",
      "for row 327, spam_prob: 0.5032331326161779, ham_prob: 0.49676686738382214\n",
      "for row 328, spam_prob: 0.8050331071950154, ham_prob: 0.19496689280498455\n",
      "for row 329, spam_prob: 0.4638056109114582, ham_prob: 0.5361943890885418\n",
      "for row 330, spam_prob: 0.1911500386464798, ham_prob: 0.8088499613535202\n",
      "for row 331, spam_prob: 0.9687535077026708, ham_prob: 0.031246492297329287\n",
      "for row 332, spam_prob: 0.5758145548640895, ham_prob: 0.4241854451359105\n",
      "for row 333, spam_prob: 0.4821586710919256, ham_prob: 0.5178413289080743\n",
      "for row 334, spam_prob: 0.9890282711040139, ham_prob: 0.010971728895985994\n",
      "for row 335, spam_prob: 0.6430039536003581, ham_prob: 0.3569960463996419\n",
      "for row 336, spam_prob: 0.7048950526713595, ham_prob: 0.29510494732864045\n",
      "for row 337, spam_prob: 0.49901690485244005, ham_prob: 0.50098309514756\n",
      "for row 338, spam_prob: 0.43123202608202216, ham_prob: 0.5687679739179778\n",
      "for row 339, spam_prob: 0.2131122700347945, ham_prob: 0.7868877299652055\n",
      "for row 340, spam_prob: 0.02264016062790578, ham_prob: 0.9773598393720943\n",
      "for row 341, spam_prob: 0.918356875251599, ham_prob: 0.08164312474840085\n",
      "for row 342, spam_prob: 0.06242120693965102, ham_prob: 0.937578793060349\n",
      "for row 343, spam_prob: 0.2775362523610085, ham_prob: 0.7224637476389916\n",
      "for row 344, spam_prob: 0.9067107974036006, ham_prob: 0.0932892025963993\n",
      "for row 345, spam_prob: 0.9813780472903462, ham_prob: 0.018621952709653864\n",
      "for row 346, spam_prob: 0.6507878247673097, ham_prob: 0.3492121752326904\n",
      "for row 347, spam_prob: 0.28652921889701244, ham_prob: 0.7134707811029876\n",
      "for row 348, spam_prob: 0.28264092896498033, ham_prob: 0.7173590710350197\n",
      "for row 349, spam_prob: 0.07354110972320999, ham_prob: 0.9264588902767901\n",
      "for row 350, spam_prob: 0.5400152943658209, ham_prob: 0.45998470563417904\n",
      "for row 351, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 352, spam_prob: 0.8016098116586088, ham_prob: 0.19839018834139124\n",
      "for row 353, spam_prob: 0.02264016062790578, ham_prob: 0.9773598393720943\n",
      "for row 354, spam_prob: 0.7535324612603126, ham_prob: 0.2464675387396874\n",
      "for row 355, spam_prob: 0.3465889834602426, ham_prob: 0.6534110165397574\n",
      "for row 356, spam_prob: 0.8617764092667752, ham_prob: 0.13822359073322477\n",
      "for row 357, spam_prob: 0.2033723730716192, ham_prob: 0.7966276269283808\n",
      "for row 358, spam_prob: 0.3764324623753789, ham_prob: 0.6235675376246211\n",
      "for row 359, spam_prob: 0.09501374774753772, ham_prob: 0.9049862522524622\n",
      "for row 360, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 361, spam_prob: 0.05041472706844717, ham_prob: 0.9495852729315529\n",
      "for row 362, spam_prob: 0.12276830304443467, ham_prob: 0.8772316969555652\n",
      "for row 363, spam_prob: 0.540833943017058, ham_prob: 0.4591660569829421\n",
      "for row 364, spam_prob: 0.025001087865195074, ham_prob: 0.9749989121348049\n",
      "for row 365, spam_prob: 0.9413153768628651, ham_prob: 0.05868462313713487\n",
      "for row 366, spam_prob: 0.8812542412342043, ham_prob: 0.11874575876579573\n",
      "for row 367, spam_prob: 0.367090134310153, ham_prob: 0.6329098656898469\n",
      "for row 368, spam_prob: 0.1619487169735581, ham_prob: 0.8380512830264419\n",
      "for row 369, spam_prob: 0.46182119991116616, ham_prob: 0.5381788000888339\n",
      "for row 370, spam_prob: 0.2401681154306607, ham_prob: 0.7598318845693394\n",
      "for row 371, spam_prob: 0.0706749569776672, ham_prob: 0.9293250430223328\n",
      "for row 372, spam_prob: 0.31326205581019845, ham_prob: 0.6867379441898015\n",
      "for row 373, spam_prob: 0.37752741718494887, ham_prob: 0.6224725828150511\n",
      "for row 374, spam_prob: 0.856121385613445, ham_prob: 0.14387861438655503\n",
      "for row 375, spam_prob: 0.32866176078321574, ham_prob: 0.6713382392167843\n",
      "for row 376, spam_prob: 0.21197213595962044, ham_prob: 0.7880278640403795\n",
      "for row 377, spam_prob: 0.9629345281383946, ham_prob: 0.03706547186160529\n",
      "for row 378, spam_prob: 0.9556117600259985, ham_prob: 0.04438823997400156\n",
      "for row 379, spam_prob: 0.7325573157654903, ham_prob: 0.2674426842345097\n",
      "for row 380, spam_prob: 0.8331129212731051, ham_prob: 0.16688707872689498\n",
      "for row 381, spam_prob: 0.1560885423160036, ham_prob: 0.8439114576839963\n",
      "for row 382, spam_prob: 0.2940360669751982, ham_prob: 0.7059639330248018\n",
      "for row 383, spam_prob: 0.8460641069662694, ham_prob: 0.15393589303373048\n",
      "for row 384, spam_prob: 0.3739591164922185, ham_prob: 0.6260408835077815\n",
      "for row 385, spam_prob: 0.891620588157786, ham_prob: 0.10837941184221403\n",
      "for row 386, spam_prob: 0.9821039346782334, ham_prob: 0.017896065321766637\n",
      "for row 387, spam_prob: 0.5951240985283447, ham_prob: 0.4048759014716552\n",
      "for row 388, spam_prob: 0.07569999967515889, ham_prob: 0.924300000324841\n",
      "for row 389, spam_prob: 0.3837643398395436, ham_prob: 0.6162356601604564\n",
      "for row 390, spam_prob: 0.5500588748928983, ham_prob: 0.4499411251071017\n",
      "for row 391, spam_prob: 0.732495567140625, ham_prob: 0.267504432859375\n",
      "for row 392, spam_prob: 0.9842959062947341, ham_prob: 0.01570409370526586\n",
      "for row 393, spam_prob: 0.04195130123475232, ham_prob: 0.9580486987652477\n",
      "for row 394, spam_prob: 0.0009333498361194076, ham_prob: 0.9990666501638806\n",
      "for row 395, spam_prob: 0.9198106100945512, ham_prob: 0.08018938990544873\n",
      "for row 396, spam_prob: 0.8905222966792923, ham_prob: 0.10947770332070768\n",
      "for row 397, spam_prob: 0.9779340542751678, ham_prob: 0.022065945724832198\n",
      "for row 398, spam_prob: 0.9545454824036931, ham_prob: 0.04545451759630689\n",
      "for row 399, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 400, spam_prob: 0.05373528979704432, ham_prob: 0.9462647102029558\n",
      "for row 401, spam_prob: 0.9576531112337074, ham_prob: 0.04234688876629251\n",
      "for row 402, spam_prob: 0.18254133325501795, ham_prob: 0.817458666744982\n",
      "for row 403, spam_prob: 0.3302832363629589, ham_prob: 0.6697167636370411\n",
      "for row 404, spam_prob: 0.8894273280388214, ham_prob: 0.11057267196117851\n",
      "for row 405, spam_prob: 0.7548482541835876, ham_prob: 0.24515174581641247\n",
      "for row 406, spam_prob: 0.9823083049044232, ham_prob: 0.017691695095576786\n",
      "for row 407, spam_prob: 0.04963544055162814, ham_prob: 0.9503645594483718\n",
      "for row 408, spam_prob: 0.8542078639334559, ham_prob: 0.14579213606654404\n",
      "for row 409, spam_prob: 0.20319298004706327, ham_prob: 0.7968070199529367\n",
      "for row 410, spam_prob: 0.1405964558433147, ham_prob: 0.8594035441566853\n",
      "for row 411, spam_prob: 0.34401962744609055, ham_prob: 0.6559803725539096\n",
      "for row 412, spam_prob: 0.891620588157786, ham_prob: 0.10837941184221403\n",
      "for row 413, spam_prob: 0.977854341691541, ham_prob: 0.02214565830845901\n",
      "for row 414, spam_prob: 0.0004060060399258976, ham_prob: 0.9995939939600741\n",
      "for row 415, spam_prob: 0.9831274207810756, ham_prob: 0.016872579218924353\n",
      "for row 416, spam_prob: 0.09127086505147461, ham_prob: 0.9087291349485254\n",
      "for row 417, spam_prob: 0.9317594952293721, ham_prob: 0.06824050477062799\n",
      "for row 418, spam_prob: 0.09618749442540155, ham_prob: 0.9038125055745984\n",
      "for row 419, spam_prob: 0.8826515928893197, ham_prob: 0.1173484071106803\n",
      "for row 420, spam_prob: 0.6093311592696554, ham_prob: 0.39066884073034464\n",
      "for row 421, spam_prob: 0.39579448777001874, ham_prob: 0.6042055122299812\n",
      "for row 422, spam_prob: 0.977854341691541, ham_prob: 0.02214565830845901\n",
      "for row 423, spam_prob: 0.8302949701853921, ham_prob: 0.1697050298146079\n",
      "for row 424, spam_prob: 0.5483793239420881, ham_prob: 0.451620676057912\n",
      "for row 425, spam_prob: 0.9313544706149994, ham_prob: 0.06864552938500061\n",
      "for row 426, spam_prob: 0.24246731872706692, ham_prob: 0.7575326812729332\n",
      "for row 427, spam_prob: 0.7650335418477368, ham_prob: 0.23496645815226325\n",
      "for row 428, spam_prob: 0.38840836701641546, ham_prob: 0.6115916329835844\n",
      "for row 429, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 430, spam_prob: 0.483134190457642, ham_prob: 0.516865809542358\n",
      "for row 431, spam_prob: 0.855709530091295, ham_prob: 0.14429046990870498\n",
      "for row 432, spam_prob: 0.3362859888826234, ham_prob: 0.6637140111173766\n",
      "for row 433, spam_prob: 0.02754551232778974, ham_prob: 0.9724544876722103\n",
      "for row 434, spam_prob: 0.9228340718619502, ham_prob: 0.07716592813804989\n",
      "for row 435, spam_prob: 0.540723691925808, ham_prob: 0.4592763080741919\n",
      "for row 436, spam_prob: 0.3812385998103661, ham_prob: 0.6187614001896339\n",
      "for row 437, spam_prob: 0.5960828828164131, ham_prob: 0.40391711718358686\n",
      "for row 438, spam_prob: 0.9737792456525206, ham_prob: 0.02622075434747949\n",
      "for row 439, spam_prob: 0.5717594440827949, ham_prob: 0.4282405559172051\n",
      "for row 440, spam_prob: 0.5434707081387696, ham_prob: 0.4565292918612304\n",
      "for row 441, spam_prob: 0.0778795010605168, ham_prob: 0.9221204989394832\n",
      "for row 442, spam_prob: 0.8552097298677638, ham_prob: 0.14479027013223633\n",
      "for row 443, spam_prob: 0.37288306509906477, ham_prob: 0.6271169349009351\n",
      "for row 444, spam_prob: 0.42984872689801246, ham_prob: 0.5701512731019875\n",
      "for row 445, spam_prob: 0.8930664831427677, ham_prob: 0.10693351685723233\n",
      "for row 446, spam_prob: 0.3031961949841965, ham_prob: 0.6968038050158036\n",
      "for row 447, spam_prob: 0.0020333785502298168, ham_prob: 0.9979666214497702\n",
      "for row 448, spam_prob: 0.9247948245693299, ham_prob: 0.07520517543067014\n",
      "for row 449, spam_prob: 0.9784155159363945, ham_prob: 0.021584484063605483\n",
      "for row 450, spam_prob: 0.7886197178875213, ham_prob: 0.21138028211247883\n",
      "for row 451, spam_prob: 0.5711691577105715, ham_prob: 0.42883084228942836\n",
      "for row 452, spam_prob: 0.05485949510608143, ham_prob: 0.9451405048939187\n",
      "for row 453, spam_prob: 0.1661550094282225, ham_prob: 0.8338449905717775\n",
      "for row 454, spam_prob: 0.9346078771834133, ham_prob: 0.06539212281658681\n",
      "for row 455, spam_prob: 0.9885943143221491, ham_prob: 0.01140568567785083\n",
      "for row 456, spam_prob: 0.043842305489706045, ham_prob: 0.956157694510294\n",
      "for row 457, spam_prob: 0.9402268730938118, ham_prob: 0.05977312690618826\n",
      "for row 458, spam_prob: 0.9618062248484417, ham_prob: 0.038193775151558314\n",
      "for row 459, spam_prob: 0.9719529980360124, ham_prob: 0.02804700196398758\n",
      "for row 460, spam_prob: 0.6028060572586217, ham_prob: 0.39719394274137837\n",
      "for row 461, spam_prob: 0.0007919856894399276, ham_prob: 0.99920801431056\n",
      "for row 462, spam_prob: 0.02590559094308206, ham_prob: 0.9740944090569179\n",
      "for row 463, spam_prob: 0.540723691925808, ham_prob: 0.4592763080741919\n",
      "for row 464, spam_prob: 0.9076864185980995, ham_prob: 0.09231358140190038\n",
      "for row 465, spam_prob: 0.0014727156488915085, ham_prob: 0.9985272843511084\n",
      "for row 466, spam_prob: 0.1555702071492568, ham_prob: 0.8444297928507432\n",
      "for row 467, spam_prob: 0.0006752248199205153, ham_prob: 0.9993247751800794\n",
      "for row 468, spam_prob: 0.7633502082374787, ham_prob: 0.23664979176252127\n",
      "for row 469, spam_prob: 0.6296675126175925, ham_prob: 0.3703324873824075\n",
      "for row 470, spam_prob: 0.4290216044441173, ham_prob: 0.5709783955558826\n",
      "for row 471, spam_prob: 0.49121698666132363, ham_prob: 0.5087830133386764\n",
      "for row 472, spam_prob: 0.3030317146245871, ham_prob: 0.6969682853754129\n",
      "for row 473, spam_prob: 0.9940213530490061, ham_prob: 0.005978646950993851\n",
      "for row 474, spam_prob: 0.801855181429828, ham_prob: 0.198144818570172\n",
      "for row 475, spam_prob: 0.23808861578162557, ham_prob: 0.7619113842183745\n",
      "for row 476, spam_prob: 0.3675523027723718, ham_prob: 0.6324476972276283\n",
      "for row 477, spam_prob: 0.5122007083315934, ham_prob: 0.4877992916684067\n",
      "for row 478, spam_prob: 0.18631915466898397, ham_prob: 0.8136808453310159\n",
      "for row 479, spam_prob: 0.8399194628296056, ham_prob: 0.16008053717039447\n",
      "for row 480, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 481, spam_prob: 0.6532758881633567, ham_prob: 0.3467241118366433\n",
      "for row 482, spam_prob: 0.9273725933995993, ham_prob: 0.07262740660040068\n",
      "for row 483, spam_prob: 0.4256366181110211, ham_prob: 0.574363381888979\n",
      "for row 484, spam_prob: 0.8526892615600136, ham_prob: 0.1473107384399865\n",
      "for row 485, spam_prob: 0.0004077058227420833, ham_prob: 0.999592294177258\n",
      "for row 486, spam_prob: 0.9304890760094352, ham_prob: 0.0695109239905647\n",
      "for row 487, spam_prob: 0.6401747833864098, ham_prob: 0.3598252166135903\n",
      "for row 488, spam_prob: 0.8324973371510311, ham_prob: 0.16750266284896886\n",
      "for row 489, spam_prob: 0.4170128643586112, ham_prob: 0.5829871356413889\n",
      "for row 490, spam_prob: 0.6029594846178373, ham_prob: 0.3970405153821628\n",
      "for row 491, spam_prob: 0.2086100421218331, ham_prob: 0.7913899578781668\n",
      "for row 492, spam_prob: 0.0395740971998156, ham_prob: 0.9604259028001844\n",
      "for row 493, spam_prob: 0.5, ham_prob: 0.5\n",
      "for row 494, spam_prob: 0.15927696703533561, ham_prob: 0.8407230329646643\n",
      "for row 495, spam_prob: 0.1258721087636719, ham_prob: 0.8741278912363282\n",
      "for row 496, spam_prob: 0.16966918561470554, ham_prob: 0.8303308143852945\n",
      "for row 497, spam_prob: 0.3925752806051193, ham_prob: 0.6074247193948806\n",
      "for row 498, spam_prob: 0.4424174675063041, ham_prob: 0.5575825324936959\n",
      "for row 499, spam_prob: 0.4547859103243928, ham_prob: 0.5452140896756072\n",
      "p_shape (500,)\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1\n",
      " 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
      " 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
      " 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0\n",
      " 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1\n",
      " 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
      " 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1\n",
      " 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0\n",
      " 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "# class_predictions = predict(training_spam[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "class_predictions = predict(testing_spam[:, 1:], log_class_priors, log_class_conditional_likelihoods)\n",
    "\n",
    "print(class_predictions)\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(class_predictions, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(class_predictions.shape == (500,))\n",
    "# assert(class_predictions.shape == (1000,))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(np.all(np.logical_or(class_predictions == 0, class_predictions == 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now test your `predict` function by classifying messages. You can do this to the *training* data, but you should also try it on the *testing* data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.868\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy\n",
    "true_classes = testing_spam[:, 0]\n",
    "# true_classes = training_spam[:, 0]\n",
    "# true_classes = np.array([1, 0, 0, 1, 1,1])\n",
    "training_set_accuracy = np.mean(np.equal(class_predictions, true_classes))\n",
    "print(f\"Accuracy on the training set: {training_set_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once you are done, you can move the code into the main assignment notebook.\n",
    "\n",
    "One way to do this is to follow the rough structure of the class that already exists in that notebook. You can use the `train` method to pass in the data and perform all of the steps before the prediction. You should store data in instance variables, e.g. `self.log_class_priors` and `self.log_class_conditional_likelihoods`. This means that then you can set up the `predict` method to match the one above without needing to pass in the additional variables. **Important:** the predict method must only take a single variable as a parameter (the one called `new_data`) in the skeleton code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
